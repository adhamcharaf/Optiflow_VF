"""
Page 3 - PrÃ©dictions et AmÃ©lioration Continue
SystÃ¨me de validation des anomalies et calcul du MAPE propre
"""

import streamlit as st
import pandas as pd
import sys
from pathlib import Path
from datetime import datetime, timedelta
import subprocess
import plotly.graph_objects as go
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Ajouter les chemins nÃ©cessaires
sys.path.append(str(Path(__file__).parent.parent.parent))
sys.path.append(str(Path(__file__).parent.parent.parent / "scripts_ml"))

# Import du dÃ©tecteur d'anomalies Prophet
from scripts_ml.prophet_anomaly_detector import ProphetAnomalyDetector

# Configuration de la page
st.set_page_config(
    page_title="Optiflow - PrÃ©dictions",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# Titre principal
st.title("ğŸ“ˆ PrÃ©dictions et AmÃ©lioration Continue")
st.markdown("---")

# Initialiser le dÃ©tecteur - PAS DE CACHE pour Ã©viter les problÃ¨mes de synchronisation
def get_detector():
    return ProphetAnomalyDetector()

detector = get_detector()

# Section principale : MÃ©triques MAPE
col1, col2, col3 = st.columns([2, 2, 1])

with col1:
    # Calculer le MAPE propre
    mape_stats = detector.calculate_clean_mape()

    # Afficher la mÃ©trique principale
    st.metric(
        label="ğŸ¯ MAPE Propre",
        value=f"{mape_stats['clean_mape']}%",
        delta=f"-{mape_stats['improvement']}%" if mape_stats['improvement'] > 0 else None,
        help="Mesure de prÃ©cision excluant les anomalies validÃ©es comme exceptionnelles"
    )

    # Description du MAPE
    st.caption("""
    ğŸ“Š **MAPE (Mean Absolute Percentage Error)** : Mesure la prÃ©cision moyenne
    des prÃ©dictions. Plus le % est bas, plus les prÃ©dictions sont prÃ©cises.
    """)

with col2:
    if mape_stats['improvement_percent'] > 0:
        st.metric(
            label="ğŸ“ˆ AmÃ©lioration",
            value=f"+{mape_stats['improvement_percent']}%",
            delta="depuis derniÃ¨re action",
            help="AmÃ©lioration du MAPE aprÃ¨s exclusion des anomalies"
        )
    else:
        st.info("Validez des anomalies pour voir l'amÃ©lioration")

with col3:
    st.metric(
        label="ğŸ” Anomalies exclues",
        value=mape_stats['anomalies_excluded'],
        help="Nombre d'anomalies marquÃ©es comme exceptionnelles"
    )

st.markdown("---")

# Section de dÃ©tection manuelle
col_left, col_right = st.columns([3, 1])

with col_left:
    st.subheader("ğŸ”„ Lancement de la DÃ©tection")

with col_right:
    if st.button("ğŸ”„ Relancer dÃ©tection", type="primary", use_container_width=True):
        with st.spinner("DÃ©tection en cours... (cela peut prendre quelques minutes)"):
            # Enregistrer le MAPE actuel comme rÃ©fÃ©rence
            detector.track_improvement()

            # Lancer la dÃ©tection
            end_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
            result = detector.detect_historical_anomalies(
                start_date="2022-01-01",
                end_date=end_date
            )

            if result['success']:
                st.success(f"âœ… DÃ©tection terminÃ©e : {result['anomalies_detected']} anomalies trouvÃ©es")
                st.rerun()
            else:
                st.error(f"âŒ Erreur : {result.get('error', 'Erreur inconnue')}")

# Section de validation des anomalies
st.subheader("ğŸ¯ Anomalies Ã  Valider")

# RÃ©cupÃ©rer les anomalies en attente
pending_anomalies = detector.get_pending_anomalies(limit=20)

if pending_anomalies:
    # CrÃ©er un DataFrame pour l'affichage
    df_anomalies = pd.DataFrame(pending_anomalies)

    # Formater les colonnes
    df_anomalies['deviation_percent'] = df_anomalies['deviation_percent'].round(1)
    df_anomalies['predicted_value'] = df_anomalies['predicted_value'].round(1)
    df_anomalies['actual_value'] = df_anomalies['actual_value'].round(1)

    # Ajouter une colonne d'Ã©cart visuel
    df_anomalies['Ã‰cart'] = df_anomalies.apply(
        lambda x: f"{'ğŸ“ˆ' if x['anomaly_type'] == 'spike' else 'ğŸ“‰'} {x['deviation_percent']}%",
        axis=1
    )

    # Colonnes Ã  afficher
    display_columns = ['detection_date', 'product_name', 'predicted_value',
                      'actual_value', 'Ã‰cart', 'severity']

    # Renommer les colonnes pour l'affichage
    column_names = {
        'detection_date': 'Date',
        'product_name': 'Produit',
        'predicted_value': 'PrÃ©dit',
        'actual_value': 'RÃ©el',
        'severity': 'SÃ©vÃ©ritÃ©'
    }

    # Afficher le tableau avec sÃ©lection
    st.info(f"ğŸ“Š {len(pending_anomalies)} anomalies en attente de validation")

    # CrÃ©er des onglets pour les actions
    tab1, tab2 = st.tabs(["ğŸ” Validation individuelle", "âš¡ Actions groupÃ©es"])

    with tab1:
        # SÃ©lection d'une anomalie
        selected_idx = st.selectbox(
            "SÃ©lectionner une anomalie:",
            range(len(df_anomalies)),
            format_func=lambda x: f"{df_anomalies.iloc[x]['detection_date']} - {df_anomalies.iloc[x]['product_name']} ({df_anomalies.iloc[x]['Ã‰cart']})"
        )

        if selected_idx is not None:
            selected_anomaly = df_anomalies.iloc[selected_idx]

            # Afficher les dÃ©tails
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("PrÃ©dit", f"{selected_anomaly['predicted_value']:.0f}")
            with col2:
                st.metric("RÃ©el", f"{selected_anomaly['actual_value']:.0f}")
            with col3:
                st.metric("Ã‰cart", selected_anomaly['Ã‰cart'])

            # Boutons d'action
            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button("âœ… Valider", key=f"validate_{selected_anomaly['id']}", use_container_width=True):
                    try:
                        if detector.update_anomaly_status(selected_anomaly['id'], 'validated'):
                            st.success("Anomalie validÃ©e")
                            st.cache_data.clear()  # Vider le cache
                            st.rerun()
                        else:
                            st.error("Erreur lors de la validation")
                    except Exception as e:
                        st.error(f"Erreur: {str(e)}")

            with col2:
                if st.button("âŒ Ignorer", key=f"ignore_{selected_anomaly['id']}", use_container_width=True,
                           help="Marquer comme Ã©vÃ©nement exceptionnel (exclu du MAPE)"):
                    try:
                        if detector.update_anomaly_status(selected_anomaly['id'], 'ignored'):
                            st.success("Anomalie ignorÃ©e - MAPE recalculÃ©")
                            st.cache_data.clear()  # Vider le cache
                            st.rerun()
                        else:
                            st.error("Erreur lors de l'ignorance")
                    except Exception as e:
                        st.error(f"Erreur: {str(e)}")

            with col3:
                if st.button("ğŸ”„ Saisonnier", key=f"seasonal_{selected_anomaly['id']}", use_container_width=True,
                           help="Marquer comme pattern rÃ©current"):
                    try:
                        if detector.update_anomaly_status(selected_anomaly['id'], 'seasonal'):
                            st.success("MarquÃ© comme saisonnier")
                            st.cache_data.clear()  # Vider le cache
                            st.rerun()
                        else:
                            st.error("Erreur lors du marquage saisonnier")
                    except Exception as e:
                        st.error(f"Erreur: {str(e)}")

    with tab2:
        st.write("Actions rapides sur plusieurs anomalies:")

        # Filtres pour actions groupÃ©es
        severity_filter = st.multiselect(
            "Filtrer par sÃ©vÃ©ritÃ©:",
            options=['low', 'medium', 'high', 'critical'],
            default=['high', 'critical']
        )

        filtered_df = df_anomalies[df_anomalies['severity'].isin(severity_filter)] if severity_filter else df_anomalies

        st.dataframe(
            filtered_df[display_columns].rename(columns=column_names),
            hide_index=True,
            use_container_width=True
        )

        # Actions groupÃ©es
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("âœ… Valider toutes (filtrÃ©es)", use_container_width=True):
                try:
                    count = 0
                    errors = 0
                    for _, row in filtered_df.iterrows():
                        try:
                            if detector.update_anomaly_status(row['id'], 'validated'):
                                count += 1
                        except Exception as e:
                            errors += 1
                            logger.error(f"Erreur validation ID {row['id']}: {e}")

                    if count > 0:
                        st.success(f"{count} anomalies validÃ©es")
                    if errors > 0:
                        st.warning(f"{errors} erreurs rencontrÃ©es")

                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"Erreur globale: {str(e)}")

        with col2:
            if st.button("âŒ Ignorer toutes (filtrÃ©es)", use_container_width=True):
                try:
                    count = 0
                    errors = 0
                    for _, row in filtered_df.iterrows():
                        try:
                            if detector.update_anomaly_status(row['id'], 'ignored'):
                                count += 1
                        except Exception as e:
                            errors += 1
                            logger.error(f"Erreur ignorance ID {row['id']}: {e}")

                    if count > 0:
                        st.success(f"{count} anomalies ignorÃ©es")
                    if errors > 0:
                        st.warning(f"{errors} erreurs rencontrÃ©es")

                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"Erreur globale: {str(e)}")

        with col3:
            if st.button("ğŸ”„ Toutes saisonniÃ¨res", use_container_width=True):
                try:
                    count = 0
                    errors = 0
                    for _, row in filtered_df.iterrows():
                        try:
                            if detector.update_anomaly_status(row['id'], 'seasonal'):
                                count += 1
                        except Exception as e:
                            errors += 1
                            logger.error(f"Erreur saisonnier ID {row['id']}: {e}")

                    if count > 0:
                        st.success(f"{count} anomalies marquÃ©es saisonniÃ¨res")
                    if errors > 0:
                        st.warning(f"{errors} erreurs rencontrÃ©es")

                    st.cache_data.clear()
                    st.rerun()
                except Exception as e:
                    st.error(f"Erreur globale: {str(e)}")

else:
    st.success("âœ… Aucune anomalie en attente de validation")
    st.info("""
    ğŸ’¡ **Pour dÃ©tecter de nouvelles anomalies:**
    1. Cliquez sur "ğŸ”„ Relancer dÃ©tection" ci-dessus
    2. Ou exÃ©cutez le script: `python scripts_ml/initialize_prophet_anomalies.py`
    """)

# Section d'historique
with st.expander("ğŸ“Š Historique des validations"):
    import sqlite3

    conn = sqlite3.connect("optiflow.db")

    # RÃ©cupÃ©rer l'historique des anomalies traitÃ©es
    query = """
    SELECT
        detection_date,
        p.name as product_name,
        predicted_value,
        actual_value,
        deviation_percent,
        anomaly_type,
        status,
        a.created_at
    FROM anomalies a
    JOIN products p ON a.product_id = p.id
    WHERE status != 'pending'
    ORDER BY a.created_at DESC
    LIMIT 50
    """

    df_history = pd.read_sql_query(query, conn)
    conn.close()

    if not df_history.empty:
        # Ajouter des icÃ´nes pour le statut
        status_icons = {
            'validated': 'âœ…',
            'ignored': 'âŒ',
            'seasonal': 'ğŸ”„'
        }
        df_history['Status'] = df_history['status'].map(lambda x: f"{status_icons.get(x, '')} {x}")

        # Formater les colonnes
        df_history['deviation_percent'] = df_history['deviation_percent'].round(1)

        st.dataframe(
            df_history[['detection_date', 'product_name', 'predicted_value',
                       'actual_value', 'deviation_percent', 'Status']],
            hide_index=True,
            use_container_width=True
        )
    else:
        st.info("Aucun historique de validation")

# Footer avec informations
st.markdown("---")
st.caption("""
**LÃ©gende des actions:**
- âœ… **Valider** : L'anomalie est normale, la garder pour l'entraÃ®nement
- âŒ **Ignorer** : Ã‰vÃ©nement exceptionnel, exclure du calcul MAPE
- ğŸ”„ **Saisonnier** : Pattern rÃ©current (NoÃ«l, soldes, etc.)
""")