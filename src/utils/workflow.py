"""
Orchestration du workflow batch nocturne selon les contraintes Optiflow
CONTRAINTE CRITIQUE: Batch nocturne obligatoire √† minuit
"""

import asyncio
import logging
import subprocess
import sys
from datetime import datetime, time
from pathlib import Path
from typing import Dict, List, Optional
from .cache import set_cached_data, CACHE_KEYS
from .database import get_db_connection

logger = logging.getLogger(__name__)

class WorkflowOrchestrator:
    """Orchestrateur du workflow batch nocturne selon les sp√©cifications"""
    
    def __init__(self, scripts_dir="scripts_ml"):
        """
        Initialise l'orchestrateur
        
        Args:
            scripts_dir: Dossier contenant les scripts ML
        """
        self.scripts_dir = Path(scripts_dir)
        self.batch_time = time(0, 30)  # 00:30 selon les specs
        self.is_running = False
        
        # Ordre d'ex√©cution selon les specs (Page 1, section Notes d'impl√©mentation)
        self.execution_order = [
            # 1. G√©n√©ration des pr√©dictions (base pour tout le reste)
            "predict_daily_sales.py",
            
            # 2. Enrichissement avec √©v√©nements
            "evaluate_events_impact.py",
            
            # 3. Calcul des alertes bas√© sur les pr√©dictions
            "calculate_alerts.py",
            
            # 4. Agr√©gation pour le dashboard
            "aggregate_dashboard_kpis.py",
            
            # 5. Monitoring des performances
            "monitor_ml_performance.py",
            
            # 6. Scripts dashboard compl√©mentaires
            "compare_ca_predictions.py",
            "calculate_trends.py",
            "get_top_urgent.py",
            "get_stock_dormant.py",
            
            # 7. Scripts pr√©dictions (Page 3)
            "generate_predictions.py",
            "calculate_accuracy.py"
        ]
    
    async def run_batch_process(self):
        """Ex√©cute le processus batch complet selon l'orchestration des specs"""
        if self.is_running:
            logger.warning("Batch d√©j√† en cours d'ex√©cution")
            return False
        
        self.is_running = True
        start_time = datetime.now()
        
        logger.info("üöÄ D√©but du processus batch nocturne")
        
        try:
            results = {}
            
            # Ex√©cution s√©quentielle selon l'ordre d√©fini
            for script_name in self.execution_order:
                script_path = self.scripts_dir / script_name
                
                if not script_path.exists():
                    logger.warning(f"‚ö†Ô∏è Script non trouv√©: {script_name}")
                    continue
                
                logger.info(f"‚ñ∂Ô∏è Ex√©cution: {script_name}")
                result = await self._run_script(script_path)
                results[script_name] = result
                
                if not result['success']:
                    logger.error(f"‚ùå √âchec: {script_name} - {result['error']}")
                    # Continuer malgr√© les erreurs selon les specs
                else:
                    logger.info(f"‚úÖ Succ√®s: {script_name}")
            
            # Mise √† jour du cache avec les r√©sultats
            await self._update_cache_with_results(results)
            
            # Enregistrement des m√©triques de performance
            duration = datetime.now() - start_time
            await self._log_batch_performance(duration, results)
            
            logger.info(f"üéâ Batch termin√© en {duration.total_seconds():.1f}s")
            return True
            
        except Exception as e:
            logger.error(f"üí• Erreur batch: {e}")
            return False
        
        finally:
            self.is_running = False
    
    async def _run_script(self, script_path: Path) -> Dict:
        """
        Ex√©cute un script ML de mani√®re asynchrone
        
        Args:
            script_path: Chemin vers le script
            
        Returns:
            Dictionnaire avec r√©sultat et m√©tadonn√©es
        """
        try:
            # Ex√©cution du script Python
            process = await asyncio.create_subprocess_exec(
                sys.executable, str(script_path),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            return {
                'success': process.returncode == 0,
                'returncode': process.returncode,
                'stdout': stdout.decode() if stdout else '',
                'stderr': stderr.decode() if stderr else '',
                'script': script_path.name
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'script': script_path.name
            }
    
    async def _update_cache_with_results(self, results: Dict):
        """Met √† jour le cache avec les r√©sultats du batch"""
        try:
            # Simulation de mise √† jour du cache avec les r√©sultats
            # TODO: Impl√©menter la logique r√©elle de mise √† jour selon les outputs des scripts
            
            # Exemple: Si predict_daily_sales.py a r√©ussi, on met √† jour le cache des pr√©dictions
            if results.get('predict_daily_sales.py', {}).get('success'):
                # Charger les nouvelles pr√©dictions et les mettre en cache
                pass
            
            # Mettre √† jour le timestamp global du cache
            cache_update_time = datetime.now().isoformat()
            set_cached_data('last_batch_run', {
                'timestamp': cache_update_time,
                'success_count': sum(1 for r in results.values() if r.get('success')),
                'total_scripts': len(results)
            })
            
            logger.info("üì¶ Cache mis √† jour avec les r√©sultats du batch")
            
        except Exception as e:
            logger.error(f"Erreur mise √† jour cache: {e}")
    
    async def _log_batch_performance(self, duration, results):
        """Enregistre les m√©triques de performance du batch"""
        try:
            performance_data = {
                'timestamp': datetime.now().isoformat(),
                'duration_seconds': duration.total_seconds(),
                'scripts_executed': len(results),
                'scripts_success': sum(1 for r in results.values() if r.get('success')),
                'scripts_failed': sum(1 for r in results.values() if not r.get('success')),
                'details': results
            }
            
            # Enregistrement dans le cache pour monitoring
            set_cached_data('batch_performance', performance_data)
            
            logger.info(f"üìä Performance batch enregistr√©e: {performance_data['scripts_success']}/{performance_data['scripts_executed']} succ√®s")
            
        except Exception as e:
            logger.error(f"Erreur logging performance: {e}")
    
    def schedule_batch(self):
        """Programme l'ex√©cution du batch nocturne"""
        # TODO: Impl√©menter la planification r√©elle (cron, scheduler, etc.)
        logger.info(f"üìÖ Batch programm√© pour {self.batch_time}")
    
    async def run_on_demand_script(self, script_name: str, params: Optional[Dict] = None):
        """
        Ex√©cute un script ML √† la demande (hors batch)
        
        Args:
            script_name: Nom du script √† ex√©cuter
            params: Param√®tres optionnels
            
        Returns:
            R√©sultat de l'ex√©cution
        """
        script_path = self.scripts_dir / script_name
        
        if not script_path.exists():
            return {'success': False, 'error': f'Script non trouv√©: {script_name}'}
        
        logger.info(f"üîÑ Ex√©cution √† la demande: {script_name}")
        result = await self._run_script(script_path)
        
        # Mise √† jour partielle du cache si n√©cessaire
        if result['success']:
            await self._update_cache_for_script(script_name, result)
        
        return result
    
    async def _update_cache_for_script(self, script_name: str, result: Dict):
        """Met √† jour le cache pour un script sp√©cifique"""
        # Mapping script -> cl√© de cache selon les specs
        script_cache_mapping = {
            'calculate_alerts.py': CACHE_KEYS['alerts'],
            'aggregate_dashboard_kpis.py': CACHE_KEYS['dashboard_kpis'],
            'predict_daily_sales.py': 'predictions_data',
            # TODO: Compl√©ter le mapping pour tous les scripts
        }
        
        cache_key = script_cache_mapping.get(script_name)
        if cache_key:
            # TODO: Parser le r√©sultat du script et mettre √† jour le cache appropri√©
            logger.info(f"üì¶ Cache mis √† jour pour {script_name} -> {cache_key}")

# Instance globale pour l'application
workflow = WorkflowOrchestrator()

async def run_daily_batch():
    """Fonction utilitaire pour lancer le batch quotidien"""
    return await workflow.run_batch_process()

async def run_script_on_demand(script_name: str, params: Optional[Dict] = None):
    """Fonction utilitaire pour lancer un script √† la demande"""
    return await workflow.run_on_demand_script(script_name, params)

def is_batch_running():
    """V√©rifie si le batch est en cours d'ex√©cution"""
    return workflow.is_running

# Configuration pour l'ex√©cution en production
class BatchScheduler:
    """Planificateur pour le batch nocturne en production"""
    
    def __init__(self):
        self.is_scheduled = False
    
    def start_scheduler(self):
        """D√©marre la planification du batch nocturne"""
        # TODO: Impl√©menter avec APScheduler ou cron
        logger.info("üìÖ Planificateur batch d√©marr√©")
        self.is_scheduled = True
    
    def stop_scheduler(self):
        """Arr√™te la planification"""
        logger.info("‚èπÔ∏è Planificateur batch arr√™t√©")
        self.is_scheduled = False